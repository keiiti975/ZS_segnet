プレビュー:control+shift+m  

---
--- *11/14* ---  
Zero-Shot Learning via Latent Similarity Embedding  
○Abstruct  
ZSRはソースドメインでの未知クラスの情報を利用してターゲットドメインの物体のクラスラベルを予測しようとするもの  
私達の識別器はクラスに依存しません  
入力と出力クラスが同じ必要はありません  
事後確率が合致するようなモデルを作り、隠れ確率モデルを提案します  
辞書学習に基づいた両方のドメインを同時に学習できる同時差分学習のフレームを作りました

1.Introduction  
ZSRは未知クラスの識別を行うのに用いられる  
これはラベルの数が多い規模の大きな分類や、ラベルの欠けているものがあるときの分類に有用である  
ソースドメインにはクラスのベクトルの集合を用いて、ターゲットドメインには物体間の距離を用いる  
学習中には既知クラスの情報しか与えない  
テスト中はソースドメインに未知クラスの間接的な情報が与えられ、ターゲットクラスに未知クラスの物体が与えられる  
テスト中の目的は未知クラスの物体のラベルを予測することである  
またクラスラベルに関わらないソースとターゲットの間の相関関数が存在する

物体の組が同じものを示している場合、クラスラベルに関わらずソースとターゲットの物体に関して確率的な相関パターンが存在する  
例えば"zebra"の画像に対して、テキストにおける"zebra"の表現は相関関数を用いて予測できる  
数学的に上記を定式化するため、バイナリ分類問題としてZSRを定式化しました  
任意のソース・ターゲットの組を用いてスコア関数を学習、そしてソースとターゲットの相関スコアを出力する  
こうすることで実際のクラスラベルに依存しない未知クラスの相関スコアを出力できる  

○Related Work  
i)Attribute prediction  
ターゲットドメインのデータをソースドメインの属性空間に埋め込む手法  
こうした手法はノイズに弱く、あまり良い分類結果が得られない  
ii)Linear Embedding  
ソースとターゲットドメインのデータを特徴空間に埋め込む手法  
iii)Nonlinear Embedding  
ii)と同様に、元の特徴を非線形にマッピングしたあとに特徴空間に埋め込む手法  
埋め込みベクトルに基づく手法と異なり、私達の手法では両方のドメインの同時隠れ空間を構造学習に基づいて学習します  

※構造予測  
-形態素解析(mecabなど)  
-単語の係り受け解析(cabochaなど)  
-webページのランキング(Learning to rank)  
-二部グラフマッチング(機械翻訳)  
多値分類では精度が大きく下がる、入力だけでなく出力の構造も特徴量に組み込んで精度を上げることができる  
タスクが難しいほど精度に差が出る  
○構造化パーセプトロン  
w\*=w+f(x,y)-f(x,y\*)  
正解の特徴量ベクトルを足して、予測したものの特徴量ベクトルを引く

2.Our Method  
○Problem Setting  
ZSRはテスト時に未知クラスのソースドメインが公開されるため、クラスラベルに関係するものが明確でない  
よってターゲットドメインの物体をソースドメインと関連付けなければならない  

○General Probabilistic Modeling  
...

---
--- *11/16* ---  
On zero-shot recognition of generic objects  
○Abstruct  
